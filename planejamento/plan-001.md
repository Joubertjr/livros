---
name: Book Summarizer Robusto - Pipeline Verific√°vel
overview: Evoluir o sistema atual para um pipeline robusto e verific√°vel que garante cobertura completa atrav√©s de Recall Sets, extra√ß√£o prim√°ria por chunks, auditoria cruzada autom√°tica e evid√™ncias estruturadas.
todos:
  - id: "0"
    content: "Definir contrato do Recall Set + Auditoria determin√≠stica: formato JSON com item_id (hash imut√°vel), critical/supporting, enum CriticalityReason, regra de marcadores [[RS:cap(\d+):hash|chunks:...]] com evid√™ncia de ancoragem, auditoria determin√≠stica com valida√ß√£o anti-fraude, coverage_report.json (PRIORIDADE 1 - BLOQUEANTE)"
    status: pending
  - id: "0.1"
    content: "Atualizar .cursorrules com regras m√≠nimas: TDD + estrutura de testes + regra de marcadores no resumo + regra de evid√™ncias"
    status: pending
  - id: "1"
    content: "Adicionar depend√™ncias de testes (pytest, pytest-cov, pytest-mock) ao requirements.txt e criar estrutura de diret√≥rios de testes (src/tests/unit/, src/tests/integration/, src/tests/fixtures/)"
    status: pending
  - id: "2"
    content: "Criar m√≥dulo chunk_extractor.py com extra√ß√£o prim√°ria estruturada por chunk (TDD: testes antes do c√≥digo, Clean Code, type hints, docstrings)"
    status: pending
  - id: "3"
    content: "Criar m√≥dulo recall_auditor.py com auditoria cruzada autom√°tica (TDD: testes antes do c√≥digo, Clean Code, type hints, docstrings)"
    status: pending
  - id: "4"
    content: "Refatorar chapter_summarizer.py: adicionar divis√£o em chunks numerados, integrar extra√ß√£o prim√°ria, gerar Recall Set, usar Recall Set no prompt, integrar auditoria com loop de regenera√ß√£o (com testes)"
    status: pending
  - id: "5"
    content: "Atualizar quality_gate.py: adicionar valida√ß√£o de cobertura (100% chunks processados, todos Recall Sets passaram na auditoria) (com testes TDD)"
    status: pending
  - id: "6"
    content: "Atualizar evidence_generator.py: adicionar relat√≥rio de cobertura estruturado (cap√≠tulos, chunks, %, Recall Sets, resultados de auditoria, logs de regenera√ß√£o) (com testes)"
    status: pending
  - id: "7"
    content: "Atualizar summarizer.py: integrar novo pipeline robusto, valida√ß√£o final antes de retornar resultado, tratamento de falhas com erro claro (com testes de integra√ß√£o)"
    status: pending
  - id: "8"
    content: "Garantir cobertura de testes >= 80% e executar todos os testes (unit√°rios e integra√ß√£o)"
    status: pending
  - id: "9"
    content: "Testar pipeline completo com livro real e validar todos os crit√©rios bin√°rios (100% chunks, Recall Sets, auditoria, evid√™ncias)"
    status: pending
  - id: "10"
    content: "Code review e refatora√ß√£o final (aplicar Clean Code, remover duplica√ß√£o, melhorar legibilidade)"
    status: pending
---

# Plano: Book Summarizer Robusto - Pipeline Verific√°vel

## An√°lise do Estado Atual vs. Demanda

### O que j√° existe:

- ‚úÖ Detec√ß√£o de cap√≠tulos (MarkdownParser)
- ‚úÖ Resumos por cap√≠tulo (ChapterSummarizer)
- ‚úÖ Resumo executivo/global
- ‚úÖ Quality Gate b√°sico (valida comprimento, conte√∫do, estrutura)
- ‚úÖ Chunking de texto (ChunkProcessor) - mas n√£o usado para cap√≠tulos
- ‚úÖ Gera√ß√£o de evid√™ncias b√°sica (EvidenceGenerator)

### O que falta (GAPS cr√≠ticos):

- ‚ùå **Etapa 1**: Cap√≠tulos n√£o s√£o divididos em chunks numerados com chunk_id
- ‚ùå **Etapa 2**: N√£o existe extra√ß√£o prim√°ria estruturada por chunk (ideias, conceitos, afirma√ß√µes, exemplos)
- ‚ùå **Etapa 3**: N√£o existe Recall Set por cap√≠tulo (lista m√≠nima obrigat√≥ria)
- ‚ùå **Etapa 4**: Resumo n√£o usa Recall Set explicitamente
- ‚ùå **Etapa 5**: N√£o existe auditoria cruzada autom√°tica (verificar se Recall Set est√° no resumo)
- ‚ùå **Etapa 6**: Resumo global j√° existe, mas precisa manter rastreabilidade
- ‚ùå Quality Gate atual √© subjetivo (palavras em comum) - n√£o prova cobertura
- ‚ùå Evid√™ncias n√£o incluem relat√≥rio de cobertura estruturado

---

## Arquitetura do Novo Pipeline

```
[PDF/MD] 
  ‚Üì
[Etapa 1: Ingest√£o Estrutural]
  ‚îú‚îÄ Detectar cap√≠tulos (j√° existe)
  ‚îî‚îÄ Dividir cada cap√≠tulo em chunks numerados (chunk_id)
  ‚Üì
[Etapa 2: Extra√ß√£o Prim√°ria por Chunk]
  ‚îú‚îÄ Para cada chunk: extrair ideias, conceitos, afirma√ß√µes, exemplos
  ‚îî‚îÄ Salvar como estrutura intermedi√°ria (JSON)
  ‚Üì
[Etapa 3: Recall Set por Cap√≠tulo]
  ‚îú‚îÄ Agregar extra√ß√µes de todos os chunks do cap√≠tulo
  ‚îî‚îÄ Gerar lista m√≠nima obrigat√≥ria (conceitos, teses, defini√ß√µes, exemplos)
  ‚Üì
[Etapa 4: Resumo do Cap√≠tulo]
  ‚îú‚îÄ Gerar resumo usando Recall Set explicitamente
  ‚îî‚îÄ Garantir que todo item do Recall Set est√° representado
  ‚Üì
[Etapa 5: Auditoria Cruzada Autom√°tica]
  ‚îú‚îÄ Verificar: "O que est√° no Recall Set e N√ÉO est√° no resumo?"
  ‚îú‚îÄ Se faltar item cr√≠tico ‚Üí ‚ùå FALHA ‚Üí üîÅ REGENERAR
  ‚îî‚îÄ Repetir at√© passar ou max tentativas
  ‚Üì
[Etapa 6: Resumo Global]
  ‚îú‚îÄ Gerar a partir dos resumos dos cap√≠tulos (j√° existe)
  ‚îî‚îÄ Manter rastreabilidade cap√≠tulo ‚Üí global
  ‚Üì
[Evid√™ncias Estruturadas]
  ‚îú‚îÄ Relat√≥rio de cobertura (cap√≠tulos, chunks, % processado)
  ‚îú‚îÄ Recall Set por cap√≠tulo
  ‚îú‚îÄ Resultado da auditoria (pass/fail)
  ‚îî‚îÄ Logs de regenera√ß√£o
```

---

## Contrato do Recall Set (DEFINIR PRIMEIRO - BLOQUEANTE)

**‚ö†Ô∏è CR√çTICO**: Este contrato deve ser definido e documentado ANTES de qualquer implementa√ß√£o. Sem isso, o sistema √© fr√°gil.

### Estrutura de Dados

```python
from enum import Enum

class CriticalityReason(Enum):
    MULTI_CHUNK = "MULTI_CHUNK"                    # Aparece em ‚â•2 chunks
    STRUCTURAL_POSITION = "STRUCTURAL_POSITION"    # Heading/t√≠tulo/primeira/√∫ltima se√ß√£o
    DEFINITION_MARKER = "DEFINITION_MARKER"         # Cont√©m marcador de defini√ß√£o
    LAW_MARKER = "LAW_MARKER"                       # √â passo/heur√≠stica/lei

@dataclass
class RecallSetItem:
    item_id: str                      # "RS:cap1:9f3a1c" (hash do conte√∫do normalizado, imut√°vel)
    content: str                      # Texto do item
    content_normalized: str           # Conte√∫do normalizado (lowercase, sem pontua√ß√£o) para hash
    level: str                        # "critical" ou "supporting"
    source_chunks: List[int]          # Chunks onde aparece (para rastreabilidade)
    criticality_reason: CriticalityReason  # Enum: MULTI_CHUNK, STRUCTURAL_POSITION, etc.

@dataclass
class ChapterRecallSet:
    chapter_number: str
    chapter_title: str
    critical_items: List[RecallSetItem]    # M√°ximo 12 itens (HARD CAP)
    supporting_items: List[RecallSetItem]  # Sem limite, mas n√£o auditado como bloqueio
    chunk_extractions: List[ChunkExtraction]  # Extra√ß√µes originais
```

### Regras de Criticidade (MEC√ÇNICAS - S√ì ENUM)

Um item √© `critical` se atender a pelo menos 1 das regras abaixo (implementa√ß√£o determin√≠stica):

1. **MULTI_CHUNK**: Aparece em ‚â•2 chunks do cap√≠tulo (sinal de import√¢ncia estrutural)
2. **STRUCTURAL_POSITION**: Est√° em heading/t√≠tulo/primeira ou √∫ltima se√ß√£o (posi√ß√£o estrutural)
3. **DEFINITION_MARKER**: Cont√©m marcador de defini√ß√£o (regex para "is/means/define", "√©/define", "significa")
4. **LAW_MARKER**: √â um passo/heur√≠stica/lei (regex para "sempre", "nunca", "regra", "portanto", "conclus√£o")

**Hard Cap**: M√°ximo 12 itens `critical` por cap√≠tulo. Se mais de 12, priorizar por:
- Frequ√™ncia (aparece em mais chunks)
- Posi√ß√£o estrutural (headings > in√≠cio > meio > fim)
- Marcadores de defini√ß√£o/lei

**IMPORTANTE**: `criticality_reason` √© SEMPRE um enum (`CriticalityReason`), nunca texto livre.

### Gera√ß√£o de item_id (DETERMIN√çSTICO E IMUT√ÅVEL)

**Regra**: `item_id = f"RS:cap{chapter_number}:{hash_curto}"`

Onde:
- `hash_curto` = primeiros 6 caracteres do hash SHA256 do `content_normalized`
- `content_normalized` = conte√∫do em lowercase, sem pontua√ß√£o, espa√ßos normalizados

**Exemplo**:
- Conte√∫do: "A dopamina √© um neurotransmissor..."
- Normalizado: "a dopamina √© um neurotransmissor"
- Hash SHA256: `9f3a1c...` (primeiros 6 chars)
- `item_id`: `RS:cap1:9f3a1c`

**Vantagem**: Reprocessar n√£o muda IDs (imut√°vel).

### Formato de Marcadores no Resumo (COM EVID√äNCIA DE ANCORAGEM)

Cada item `critical` do Recall Set DEVE aparecer no resumo com marcador e evid√™ncia de ancoragem:

**Formato obrigat√≥rio**:
```
[[RS:cap1:9f3a1c|chunks:2,4]]
```

ou

```
[[RS:cap1:9f3a1c|src:cap1_chunk_2,cap1_chunk_4]]
```

Onde:
- `RS` = Recall Set
- `cap1` = n√∫mero do cap√≠tulo
- `9f3a1c` = hash curto do conte√∫do (item_id)
- `chunks:2,4` = refer√™ncia aos chunks de origem (√≠ndices num√©ricos)
- `src:cap1_chunk_2,cap1_chunk_4` = refer√™ncia aos chunks de origem (chunk_ids)

**Regex para extra√ß√£o**: `\[\[RS:cap(\d+):([a-f0-9]{6})\|(chunks|src):([^\]]+)\]\]`

**Anti-fraude**: O marcador sem evid√™ncia de ancoragem √© INV√ÅLIDO. O auditor verifica:
1. Marcador existe ‚úÖ
2. Refer√™ncia de chunks existe ‚úÖ
3. **M√≠nimo 1 chunk**: `chunks:` ou `src:` deve ter pelo menos 1 inteiro v√°lido ‚úÖ
4. Chunks referenciados s√£o v√°lidos ‚úÖ (cada chunk deve estar em `source_chunks` do Recall Set)

### Regra de Auditoria Determin√≠stica (COM VALIDA√á√ÉO DE ANCORAGEM)

**Camada A (Determin√≠stica - OBRIGAT√ìRIA)**:
1. Extrair todos os marcadores `[[RS:cap(\d+):hash|chunks:...]]` do resumo via regex
2. Para cada marcador extra√≠do:
   - Validar que `item_id` existe no `critical_items` do Recall Set ‚úÖ
   - Validar que refer√™ncia de chunks existe (`chunks:` ou `src:`) ‚úÖ
   - **Validar m√≠nimo 1 chunk**: `chunks:` ou `src:` deve ter pelo menos 1 inteiro v√°lido ‚úÖ
   - Validar que chunks referenciados est√£o em `source_chunks` do item ‚úÖ (cada chunk deve estar na lista)
3. Comparar com `critical_items` do Recall Set:
   - Se todos os `critical_items` t√™m marcador v√°lido ‚Üí PASSA
   - Se falta qualquer marcador ‚Üí FALHA (regenerar)
   - Se marcador existe mas chunks inv√°lidos (vazio, sem chunks, ou n√£o est√£o em `source_chunks`) ‚Üí FALHA (regenerar)
4. N√£o depende de LLM, √© valida√ß√£o pura (regex + compara√ß√£o)

**Camada B (LLM opcional - N√ÉO BLOQUEANTE)**:
- Valida qualidade textual (redund√¢ncia, clareza, coes√£o)
- NUNCA valida cobertura (isso √© Camada A)
- Pode retornar score 0-1, mas n√£o bloqueia aprova√ß√£o

---

## Implementa√ß√£o Detalhada

**‚ö†Ô∏è IMPORTANTE**: Antes de implementar qualquer m√≥dulo, o **Contrato do Recall Set** (se√ß√£o anterior) deve estar completamente definido e documentado.

### 1. Novo M√≥dulo: `chunk_extractor.py`

**Responsabilidade**: Extra√ß√£o prim√°ria estruturada por chunk

**Estruturas de dados**:

```python
@dataclass
class ChunkExtraction:
    chunk_id: str                    # "cap_1_chunk_3"
    chapter_number: str
    chunk_number: int
    text: str
    ideias_centrais: List[str]       # Ideias principais do chunk
    conceitos_termos: List[str]       # Conceitos/termos importantes
    afirmacoes_autor: List[str]      # Afirma√ß√µes do autor
    exemplos_relevantes: List[str]   # Exemplos mencionados

@dataclass
class ChapterRecallSet:
    chapter_number: str
    chapter_title: str
    critical_items: List[RecallSetItem]    # M√°ximo 12 (HARD CAP)
    supporting_items: List[RecallSetItem]  # Sem limite
    chunk_extractions: List[ChunkExtraction]  # Extra√ß√µes originais
```

**M√©todos principais**:

- `extract_from_chunk(chunk_text, chunk_id) -> ChunkExtraction`: Extrai estrutura do chunk usando LLM
- `aggregate_to_recall_set(chunk_extractions) -> ChapterRecallSet`: Agrega chunks em Recall Set

**Arquivo**: `src/chunk_extractor.py`

---

### 2. Novo M√≥dulo: `recall_auditor.py`

**Responsabilidade**: Auditoria cruzada autom√°tica (DETERMIN√çSTICA)

**Estrutura**:

```python
@dataclass
class AuditResult:
    chapter_number: str
    passed: bool                      # True se todos critical_items t√™m marcador
    missing_markers: List[str]        # item_ids sem marcador [[RS:...]]
    coverage_percentage: float         # % de marcadores encontrados (critical_items)
    critical_missing: List[str]        # item_ids cr√≠ticos faltantes (mesmo que missing_markers)
    llm_quality_score: Optional[float]  # Opcional: qualidade textual (n√£o bloqueia)
```

**M√©todos principais**:

- `audit_chapter_summary_deterministic(recall_set, summary) -> AuditResult`: 
  - **Camada A (Determin√≠stica)**: Valida marcadores `[[RS:cap(\d+):hash|chunks:...]]` no resumo
  - Extrai todos os marcadores com regex: `\[\[RS:cap(\d+):([a-f0-9]{6})\|(chunks|src):([^\]]+)\]\]`
  - Para cada marcador:
    - Valida que `item_id` existe no `critical_items` ‚úÖ
    - Valida que refer√™ncia de chunks existe ‚úÖ
    - **Valida m√≠nimo 1 chunk**: `chunks:` ou `src:` deve ter pelo menos 1 inteiro v√°lido ‚úÖ
    - Valida que chunks referenciados est√£o em `source_chunks` do item ‚úÖ (cada chunk deve estar na lista)
  - Compara com `critical_items` do Recall Set
  - Retorna `passed=False` se:
    - Qualquer `critical_item` n√£o tem marcador, OU
    - Marcador existe mas chunks inv√°lidos (anti-fraude: vazio, sem chunks, ou chunks n√£o est√£o em `source_chunks`)
  
- `audit_chapter_summary_llm_quality(recall_set, summary) -> Optional[float]`:
  - **Camada B (Opcional)**: Valida qualidade textual, redund√¢ncia, clareza
  - NUNCA valida cobertura (isso √© Camada A)
  - Retorna score 0-1 ou None se n√£o executado

- `should_regenerate(audit_result) -> bool`: 
  - Retorna `True` se `audit_result.passed == False`
  - N√£o depende de LLM

**Arquivo**: `src/recall_auditor.py`

**IMPORTANTE**: A auditoria determin√≠stica (Camada A) √© OBRIGAT√ìRIA e BLOQUEANTE. A Camada B (LLM) √© opcional e n√£o bloqueia.

---

### 3. Refatorar: `chapter_summarizer.py`

**Mudan√ßas necess√°rias**:

1. **Adicionar divis√£o em chunks**:
   - M√©todo `_chunk_chapter(chapter_text) -> List[Chunk]`: Divide cap√≠tulo em chunks numerados
   - Cada chunk recebe `chunk_id` √∫nico: `f"cap_{chapter.number}_chunk_{i}"`

2. **Integrar extra√ß√£o prim√°ria**:
   - Chamar `ChunkExtractor.extract_from_chunk()` para cada chunk
   - Salvar extra√ß√µes como estrutura intermedi√°ria

3. **Gerar Recall Set**:
   - Chamar `ChunkExtractor.aggregate_to_recall_set()` ap√≥s processar todos os chunks

4. **Usar Recall Set no prompt**:
   - Modificar prompt de resumo para incluir explicitamente o Recall Set
   - **OBRIGAT√ìRIO**: Exigir que cada `critical_item` apare√ßa no resumo com marcador e evid√™ncia de ancoragem
   - Formato: `[[RS:cap(\d+):hash|chunks:N,M]]` onde `hash` √© o `item_id` e `N,M` s√£o os `source_chunks`
   - Exemplo no prompt: "Cada item cr√≠tico do Recall Set DEVE aparecer com seu marcador e chunks de origem: [[RS:cap1:9f3a1c|chunks:2,4]], [[RS:cap1:a2b3c4|chunks:1,3,5]], etc."

5. **Integrar auditoria**:
   - Ap√≥s gerar resumo, chamar `RecallAuditor.audit_chapter_summary()`
   - Se falhar, regenerar com prompt refor√ßado
   - Loop at√© passar ou max tentativas (3)

**Mudan√ßas no `ChapterSummary`**:

```python
@dataclass
class ChapterSummary:
    # ... campos existentes ...
    recall_set: ChapterRecallSet      # NOVO
    audit_result: AuditResult        # NOVO
    chunk_extractions: List[ChunkExtraction]  # NOVO
    regeneration_count: int = 0       # NOVO
```

---

### 4. Refatorar: `quality_gate.py`

**Mudan√ßas necess√°rias**:

1. **Usar `coverage_report.json` como fonte √∫nica de verdade**:
   - Quality Gate **N√ÉO recalcula** no ar
   - M√©todo `validate_from_coverage_report(coverage_report_path) -> bool`: L√™ `EVIDENCIAS/coverage_report.json`
   - Crit√©rio bin√°rio: 
     - ‚úÖ `overall_coverage_percentage == 100.0`
     - ‚úÖ `missing_critical_item_ids` vazio em TODOS os cap√≠tulos
     - ‚úÖ `total_chapters == chapters_processed`
     - ‚úÖ `total_critical_items == total_covered`

2. **Valida√ß√£o determin√≠stica**:
   - Se arquivo n√£o existe ‚Üí FALHA
   - Se estrutura JSON inv√°lida ‚Üí FALHA
   - Se qualquer crit√©rio acima falhar ‚Üí FALHA
   - N√£o depende de rec√°lculo, apenas leitura do arquivo gerado

3. **Integrar com pipeline**:
   - Quality Gate s√≥ aprova se `coverage_report.json` mostrar 100% de cobertura
   - Fonte √∫nica de verdade: o arquivo gerado, n√£o rec√°lculo em mem√≥ria

---

### 5. Refatorar: `evidence_generator.py`

**Mudan√ßas necess√°rias**:

1. **Adicionar relat√≥rio de cobertura**:
   - Se√ß√£o "Cobertura de Cap√≠tulos e Chunks"
   - Lista: cap√≠tulos processados, chunks por cap√≠tulo, % processado

2. **Adicionar Recall Sets**:
   - Se√ß√£o "Recall Sets por Cap√≠tulo"
   - Mostrar conceitos, teses, defini√ß√µes, exemplos de cada cap√≠tulo

3. **Adicionar resultados de auditoria**:
   - Se√ß√£o "Auditoria Cruzada"
   - Mostrar pass/fail por cap√≠tulo, itens faltantes, % de cobertura

4. **Adicionar logs de regenera√ß√£o**:
   - Se√ß√£o "Regenera√ß√µes"
   - Mostrar quantas vezes cada cap√≠tulo foi regenerado

5. **Gerar Matriz de Cobertura (BIN√ÅRIA)**:
   - Arquivo obrigat√≥rio: `EVIDENCIAS/coverage_report.json`
   - Estrutura bin√°ria e f√°cil de auditar (1 linha por item cr√≠tico)

**Formato de sa√≠da**: JSON estruturado + Markdown leg√≠vel + `coverage_report.json`

### Estrutura do coverage_report.json

**Arquivo obrigat√≥rio**: `EVIDENCIAS/coverage_report.json`

**Estrutura m√≠nima**:
```json
{
  "chapters": [
    {
      "chapter_number": "1",
      "chapter_title": "The Problem",
      "total_chunks": 5,
      "processed_chunks": 5,
      "critical_items_total": 8,
      "critical_items_covered": 8,
      "missing_critical_item_ids": [],
      "regeneration_count": 0,
      "coverage_percentage": 100.0,
      "items": [
        {
          "item_id": "RS:cap1:9f3a1c",
          "content_preview": "A dopamina √©...",
          "criticality_reason": "MULTI_CHUNK",
          "source_chunks": [2, 4],
          "covered": true,
          "marker_found": true,
          "chunks_validated": true
        }
      ]
    }
  ],
  "summary": {
    "total_chapters": 11,
    "chapters_processed": 11,
    "total_critical_items": 95,
    "total_covered": 95,
    "overall_coverage_percentage": 100.0
  }
}
```

**Prop√≥sito**: Painel bin√°rio do sistema. F√°cil de auditar, sem ambiguidade.

---

### 6. Atualizar: `summarizer.py`

**Mudan√ßas necess√°rias**:

1. **Integrar novo pipeline**:
   - Quando cap√≠tulos detectados, usar novo pipeline robusto
   - Garantir que todas as etapas sejam executadas em ordem

2. **Valida√ß√£o final**:
   - Antes de retornar resultado, verificar:
     - ‚úÖ 100% chunks processados
     - ‚úÖ Todo cap√≠tulo tem Recall Set
     - ‚úÖ Todo Recall Set passou na auditoria
     - ‚úÖ Evid√™ncias geradas

3. **Tratamento de falhas**:
   - Se qualquer crit√©rio falhar ‚Üí resultado inv√°lido
   - Retornar erro claro indicando qual crit√©rio falhou

---

### 7. Estrutura de Dados Intermedi√°ria

**Salvar extra√ß√µes prim√°rias**:

- Formato: JSON
- Localiza√ß√£o: `EVIDENCIAS/extractions_{timestamp}.json`
- Estrutura:
```json
{
  "chapters": [
    {
      "chapter_number": "1",
      "chapter_title": "The Problem",
      "chunks": [
        {
          "chunk_id": "cap_1_chunk_1",
          "chunk_number": 1,
          "text": "...",
          "extraction": {
            "ideias_centrais": [...],
            "conceitos_termos": [...],
            "afirmacoes_autor": [...],
            "exemplos_relevantes": [...]
          }
        }
      ],
      "recall_set": {
        "conceitos": [...],
        "teses": [...],
        "definicoes": [...],
        "exemplos": [...]
      }
    }
  ]
}
```

---

## Crit√©rios de Qualidade Bin√°rios

O sistema S√ì retorna resultado v√°lido se:

1. ‚úÖ **100% dos chunks processados**: `total_chunks == processed_chunks`
2. ‚úÖ **Todo cap√≠tulo tem Recall Set**: `len(recall_sets) == len(chapters)`
3. ‚úÖ **Todo Recall Set tem ‚â§12 itens cr√≠ticos**: `all(len(rs.critical_items) <= 12 for rs in recall_sets)`
4. ‚úÖ **Todo Recall Set passou na auditoria determin√≠stica**: `all(audit.passed for audit in audit_results)`
   - Auditoria determin√≠stica: todos `critical_items` t√™m marcador v√°lido `[[RS:cap(\d+):hash|chunks:...]]` no resumo
   - Valida√ß√£o anti-fraude: marcador existe, m√≠nimo 1 chunk v√°lido, chunks referenciados est√£o em `source_chunks`
   - N√£o depende de LLM, √© valida√ß√£o pura (regex + compara√ß√£o)
5. ‚úÖ **Nenhuma omiss√£o cr√≠tica**: `all(len(audit.critical_missing) == 0 for audit in audit_results)`
6. ‚úÖ **Evid√™ncias geradas**: Arquivo de evid√™ncia existe e √© v√°lido

Se qualquer um falhar ‚Üí **resultado inv√°lido** ‚Üí erro claro

**IMPORTANTE**: A auditoria determin√≠stica (contagem de marcadores) √© OBRIGAT√ìRIA e BLOQUEANTE. LLM pode validar qualidade textual, mas NUNCA valida cobertura.

---

## Fluxo de Execu√ß√£o

```
1. Detectar cap√≠tulos (MarkdownParser) ‚úÖ
2. Para cada cap√≠tulo:
   a. Dividir em chunks numerados
   b. Para cada chunk:
      - Extrair estrutura (ideias, conceitos, afirma√ß√µes, exemplos)
      - Salvar extra√ß√£o
   c. Agregar extra√ß√µes ‚Üí Recall Set
   d. Gerar resumo usando Recall Set
   e. Auditar resumo vs Recall Set
   f. Se falhar ‚Üí regenerar (max 3x)
3. Gerar resumo global dos resumos dos cap√≠tulos
4. Gerar evid√™ncias estruturadas (incluindo `coverage_report.json`)
5. Validar cobertura completa (Quality Gate l√™ `coverage_report.json` como fonte √∫nica)
6. Retornar resultado (ou erro se inv√°lido)
```

---

## Arquivos a Criar/Modificar

### Novos arquivos:

- `src/chunk_extractor.py` - Extra√ß√£o prim√°ria por chunk
- `src/recall_auditor.py` - Auditoria cruzada autom√°tica

### Arquivos a modificar:

- `.cursorrules` - Adicionar regras de Clean Code/TDD, estrutura de testes, regras operacionais e checklist
- `requirements.txt` ou `pyproject.toml` - Adicionar pytest, pytest-cov, pytest-mock
- `src/chapter_summarizer.py` - Integrar chunks, Recall Set, auditoria
- `src/quality_gate.py` - Adicionar valida√ß√£o de cobertura usando `coverage_report.json` como fonte √∫nica
- `src/evidence_generator.py` - Adicionar relat√≥rio de cobertura estruturado
- `src/summarizer.py` - Integrar novo pipeline e valida√ß√£o final

### Estrutura de testes a criar:

- `src/tests/unit/test_chunk_extractor.py`
- `src/tests/unit/test_recall_auditor.py`
- `src/tests/integration/test_pipeline_complete.py`
- `src/tests/fixtures/sample_chapters.json`

---

## Considera√ß√µes T√©cnicas

1. **Chunking de cap√≠tulos**:
   - Usar `ChunkProcessor` existente, mas adaptado para cap√≠tulos
   - Tamanho: 800-1200 palavras por chunk (menor que texto completo)
   - Overlap: 100 palavras

2. **Extra√ß√£o prim√°ria**:
   - Usar LLM (gpt-4o-mini) com prompt estruturado
   - Formato de resposta: JSON ou texto estruturado parse√°vel
   - Retry com backoff exponencial

3. **Recall Set**:
   - Agregar extra√ß√µes removendo duplicatas
   - Aplicar regras mec√¢nicas de criticidade (‚â•2 chunks, heading, defini√ß√£o, lei)
   - **HARD CAP**: M√°ximo 12 itens `critical` por cap√≠tulo
   - Se mais de 12, priorizar por frequ√™ncia e posi√ß√£o estrutural
   - `supporting_items` sem limite, mas n√£o auditado como bloqueio

4. **Auditoria**:
   - **Camada A (Determin√≠stica)**: Validar marcadores `[[RS:cap(\d+):hash|chunks:...]]` no resumo via regex
   - Valida√ß√£o anti-fraude: marcador existe, m√≠nimo 1 chunk v√°lido, chunks referenciados est√£o em `source_chunks`
   - Se todos `critical_items` t√™m marcador v√°lido ‚Üí PASSA
   - Se falta qualquer marcador ou chunks inv√°lidos (vazio, sem chunks, ou n√£o est√£o em `source_chunks`) ‚Üí FALHA (regenerar)
   - **Camada B (Opcional)**: LLM valida qualidade textual (redund√¢ncia, clareza)
   - LLM NUNCA valida cobertura (isso √© Camada A)

5. **Performance**:
   - Processar chunks em paralelo (dentro de cada cap√≠tulo)
   - Processar cap√≠tulos em paralelo
   - Cache de extra√ß√µes para evitar reprocessamento

---

## Testes e Valida√ß√£o

1. **Teste unit√°rio**: Extra√ß√£o prim√°ria de um chunk
2. **Teste unit√°rio**: Agrega√ß√£o de chunks em Recall Set
3. **Teste unit√°rio**: Auditoria de resumo vs Recall Set
4. **Teste de integra√ß√£o**: Pipeline completo com livro pequeno (3-5 cap√≠tulos)
5. **Teste de regress√£o**: Verificar que resumos ainda s√£o gerados corretamente

---

## Clean Code / TDD: Regras Operacionais para Desenvolvimento

### Princ√≠pios de Clean Code

1. **Nomes Significativos**:
   - Vari√°veis, fun√ß√µes e classes devem ter nomes que expressam claramente sua inten√ß√£o
   - Evitar abrevia√ß√µes desnecess√°rias
   - Exemplo: `extract_chunk_ideas()` ao inv√©s de `ext()`

2. **Fun√ß√µes Pequenas e com Responsabilidade √önica**:
   - Uma fun√ß√£o deve fazer uma coisa e fazer bem
   - M√°ximo 20-30 linhas por fun√ß√£o
   - Se uma fun√ß√£o faz mais de uma coisa, dividir em fun√ß√µes menores

3. **Coment√°rios Explicativos, n√£o √ìbvios**:
   - Coment√°rios devem explicar "por qu√™", n√£o "o qu√™"
   - C√≥digo autoexplicativo √© prefer√≠vel a coment√°rios
   - Documentar decis√µes de design e trade-offs

4. **Estruturas de Dados Simples**:
   - Preferir dataclasses para estruturas de dados
   - Evitar dicion√°rios aninhados complexos
   - Type hints obrigat√≥rios em todas as fun√ß√µes

5. **Tratamento de Erros Expl√≠cito**:
   - Nunca usar `except: pass` silencioso
   - Erros devem ser espec√≠ficos e informativos
   - Usar exce√ß√µes customizadas quando apropriado

6. **Sem Duplica√ß√£o (DRY)**:
   - Extrair c√≥digo duplicado em fun√ß√µes reutiliz√°veis
   - Usar composi√ß√£o ao inv√©s de repeti√ß√£o

7. **Separa√ß√£o de Responsabilidades**:
   - Cada m√≥dulo/classe tem uma responsabilidade clara
   - Alta coes√£o, baixo acoplamento

### Test-Driven Development (TDD)

**Ciclo Red-Green-Refactor obrigat√≥rio**:

1. **RED**: Escrever teste que falha (define comportamento esperado)
2. **GREEN**: Escrever c√≥digo m√≠nimo para passar no teste
3. **REFACTOR**: Melhorar c√≥digo mantendo testes passando

**Regras de TDD**:

1. **Teste antes do c√≥digo**:
   - Nunca escrever c√≥digo de produ√ß√£o sem teste correspondente
   - Teste define a interface e comportamento esperado

2. **Testes unit√°rios obrigat√≥rios**:
   - Cada fun√ß√£o p√∫blica deve ter pelo menos um teste
   - Cobertura m√≠nima: 80% (objetivo: 90%+)

3. **Testes de integra√ß√£o**:
   - Testar fluxo completo do pipeline
   - Testar integra√ß√£o entre m√≥dulos

4. **Testes determin√≠sticos**:
   - Sempre usar dados fixos/mocks para testes
   - N√£o depender de ordem de execu√ß√£o
   - N√£o depender de estado externo (API, arquivos)

5. **Estrutura AAA (Arrange-Act-Assert)**:
   ```python
   def test_extract_chunk_ideas():
       # Arrange
       chunk_text = "Texto de exemplo..."
       chunk_id = "cap_1_chunk_1"
       
       # Act
       result = extractor.extract_from_chunk(chunk_text, chunk_id)
       
       # Assert
       assert len(result.ideias_centrais) > 0
       assert result.chunk_id == chunk_id
   ```

6. **Testes isolados**:
   - Cada teste deve ser independente
   - N√£o compartilhar estado entre testes
   - Usar fixtures/pytest quando necess√°rio

### Estrutura de Testes

**Organiza√ß√£o**:

```
src/
  tests/
    unit/
      test_chunk_extractor.py
      test_recall_auditor.py
      test_quality_gate.py
    integration/
      test_pipeline_complete.py
      test_chapter_summarization.py
    fixtures/
      sample_chapters.json
      sample_chunks.txt
```

**Conven√ß√µes de nomenclatura**:

- Arquivos de teste: `test_*.py`
- Fun√ß√µes de teste: `test_*`
- Classes de teste: `Test*`

**Ferramentas**:

- Framework: `pytest`
- Mocks: `unittest.mock` ou `pytest-mock`
- Cobertura: `pytest-cov`
- Fixtures: `pytest.fixture`

### Regras Operacionais de Desenvolvimento

1. **Commits At√¥micos**:
   - Um commit = uma funcionalidade/teste completo
   - Mensagens claras: "feat: adiciona extra√ß√£o prim√°ria por chunk"
   - Nunca commitar c√≥digo que quebra testes

2. **Code Review Obrigat√≥rio** (se aplic√°vel):
   - Verificar: testes passando, cobertura adequada, Clean Code
   - Revisar l√≥gica, n√£o apenas sintaxe

3. **Refatora√ß√£o Cont√≠nua**:
   - Refatorar ap√≥s adicionar funcionalidade
   - Manter c√≥digo limpo a cada itera√ß√£o
   - N√£o acumular "d√≠vida t√©cnica"

4. **Documenta√ß√£o de C√≥digo**:
   - Docstrings obrigat√≥rias em todas as fun√ß√µes p√∫blicas
   - Formato: Google style ou NumPy style
   - Explicar par√¢metros, retorno e exce√ß√µes

5. **Type Hints Obrigat√≥rios**:
   ```python
   def extract_from_chunk(
       self, 
       chunk_text: str, 
       chunk_id: str
   ) -> ChunkExtraction:
       """Extrai estrutura do chunk."""
   ```

6. **Logging Estruturado**:
   - Usar `logging` module, n√£o `print()`
   - N√≠veis apropriados: DEBUG, INFO, WARNING, ERROR
   - Logs devem ser √∫teis para debugging

7. **Valida√ß√£o de Entrada**:
   - Validar todos os inputs de fun√ß√µes p√∫blicas
   - Usar `assert` para invariantes internas
   - Levantar exce√ß√µes espec√≠ficas para erros de valida√ß√£o

8. **Performance e Otimiza√ß√£o**:
   - Otimizar apenas ap√≥s medir (profiling)
   - Preferir c√≥digo leg√≠vel a micro-otimiza√ß√µes
   - Documentar trade-offs de performance

### Checklist de Desenvolvimento

Antes de considerar uma funcionalidade completa:

- [ ] C√≥digo segue princ√≠pios de Clean Code
- [ ] Testes unit√°rios escritos (TDD)
- [ ] Testes passando (100%)
- [ ] Cobertura de c√≥digo >= 80%
- [ ] Type hints em todas as fun√ß√µes
- [ ] Docstrings em fun√ß√µes p√∫blicas
- [ ] Sem c√≥digo duplicado
- [ ] Tratamento de erros adequado
- [ ] Logging estruturado implementado
- [ ] Valida√ß√£o de inputs
- [ ] Testes de integra√ß√£o (se aplic√°vel)
- [ ] Refatora√ß√£o aplicada (se necess√°rio)
- [ ] C√≥digo revisado (se aplic√°vel)

### Exemplo de C√≥digo Limpo

**‚ùå Ruim**:

```python
def proc(txt, id):
    # processa texto
    r = {}
    for w in txt.split():
        if len(w) > 4:
            r[w] = r.get(w, 0) + 1
    return r
```

**‚úÖ Bom**:

```python
def extract_key_concepts(
    chunk_text: str, 
    chunk_id: str
) -> Dict[str, int]:
    """
    Extrai conceitos-chave do chunk contando palavras significativas.
    
    Args:
        chunk_text: Texto do chunk a processar
        chunk_id: Identificador √∫nico do chunk
        
    Returns:
        Dicion√°rio com conceitos e suas frequ√™ncias
        
    Raises:
        ValueError: Se chunk_text estiver vazio
    """
    if not chunk_text or not chunk_text.strip():
        raise ValueError(f"chunk_text n√£o pode estar vazio (chunk_id: {chunk_id})")
    
    MIN_WORD_LENGTH = 4
    concept_frequencies: Dict[str, int] = {}
    
    words = chunk_text.split()
    for word in words:
        if len(word) > MIN_WORD_LENGTH:
            concept_frequencies[word] = concept_frequencies.get(word, 0) + 1
    
    return concept_frequencies
```

### Integra√ß√£o com Pipeline

**Ordem de desenvolvimento seguindo TDD**:

1. **Escrever teste para `ChunkExtractor.extract_from_chunk()`**
2. **Implementar `ChunkExtractor.extract_from_chunk()` (m√≠nimo para passar)**
3. **Refatorar c√≥digo**
4. **Escrever teste para `ChunkExtractor.aggregate_to_recall_set()`**
5. **Implementar agrega√ß√£o**
6. **Repetir para cada m√≥dulo**

**Testes de integra√ß√£o do pipeline**:

- Teste completo: PDF ‚Üí Cap√≠tulos ‚Üí Chunks ‚Üí Extra√ß√µes ‚Üí Recall Set ‚Üí Resumo ‚Üí Auditoria
- Validar que todos os crit√©rios bin√°rios s√£o verificados
- Validar que evid√™ncias s√£o geradas corretamente

---

## Atualiza√ß√£o do .cursorrules (M√çNIMA)

**Arquivo**: `.cursorrules`

**Conte√∫do M√çNIMO a adicionar** (sem luxo):

1. **TDD (Test-Driven Development)**:
   - Ciclo Red-Green-Refactor obrigat√≥rio
   - Teste antes do c√≥digo
   - Cobertura m√≠nima: 80%
   - Estrutura AAA (Arrange-Act-Assert)

2. **Estrutura de Testes**:
   - Organiza√ß√£o: `src/tests/unit/`, `src/tests/integration/`, `src/tests/fixtures/`
   - Framework: pytest
   - Conven√ß√µes: `test_*.py`, `test_*`, `Test*`

3. **Regra de Marcadores no Resumo**:
   - Cada item cr√≠tico do Recall Set DEVE aparecer no resumo com marcador e evid√™ncia de ancoragem: `[[RS:cap(\d+):hash|chunks:N,M]]`
   - Auditoria determin√≠stica valida marcadores + chunks referenciados (anti-fraude, n√£o depende de LLM)

4. **Regra de Evid√™ncias**:
   - Evid√™ncias s√£o artefato can√¥nico (sistema fala por evid√™ncia, n√£o por conversa)
   - Formato: JSON estruturado + Markdown leg√≠vel

**Ordem de atualiza√ß√£o**: Atualizar `.cursorrules` ap√≥s definir contrato do Recall Set (TODO 0)

---

## GO / NO-GO (Pr√©-Desenvolvimento)

**‚ö†Ô∏è BLOQUEANTE**: O desenvolvimento S√ì pode come√ßar se estes 3 itens estiverem 100% claros para o Cursor. Se qualquer um estiver "meio aberto", √© **NO-GO** (o Cursor vai implementar "do jeito dele" e voc√™ perde a verificabilidade).

### ‚úÖ GO se estes 3 itens est√£o claros:

1. **Contrato fechado (TODO 0)**
   - ‚úÖ Existe defini√ß√£o final do Recall Set JSON
   - ‚úÖ `CriticalityReason` enum definido
   - ‚úÖ `item_id` com hash imut√°vel definido
   - ‚úÖ Marcador com ancoragem definido: `[[RS:cap(\d+):hash|chunks:...]]`
   - ‚úÖ Auditoria determin√≠stica anti-fraude definida

2. **Evid√™ncia can√¥nica definida**
   - ‚úÖ `EVIDENCIAS/coverage_report.json` √© fonte √∫nica de verdade do Quality Gate
   - ‚úÖ Quality Gate **N√ÉO recalcula**, apenas l√™ o arquivo

3. **Regenera√ß√£o com limite**
   - ‚úÖ Loop de regenera√ß√£o: max 3 tentativas por cap√≠tulo
   - ‚úÖ Falha expl√≠cita ap√≥s 3 tentativas

**Se qualquer um desses 3 estiver "meio aberto" ‚Üí NO-GO**

---

## üî• Gates ENDFIRST (Z0 ‚Üí Z5)

**‚ö†Ô∏è ORDEM OBRIGAT√ìRIA (ENDFIRST)**: Voc√™ N√ÉO pode come√ßar pelos m√≥dulos "legais". Comece provando que o sistema n√£o consegue dar resultado sem cumprir o contrato.

**‚ö†Ô∏è CR√çTICO**: Cada gate √© **BLOQUEANTE**. N√£o avance sem: `pytest -q` passando + artefatos do gate.

### ‚úÖ Gate Z0 ‚Äî "Resumo Imposs√≠vel" (Falhas Esperadas)

**Objetivo ENDFIRST**: Criar testes de integra√ß√£o que provem que o sistema falha quando n√£o cumpre o contrato.

**Testes que devem provar falhas esperadas**:
1. N√£o existe Recall Set ‚Üí FAIL
2. N√£o existe marcador ‚Üí FAIL
3. Marcador existe mas chunks inv√°lidos ‚Üí FAIL
4. Marcador inventado (item_id n√£o existe) ‚Üí FAIL

**Entrega obrigat√≥ria**:
- ‚úÖ `src/tests/integration/test_gate_z0_impossible_summary.py`
- ‚úÖ Testes devem falhar antes da implementa√ß√£o completa (RED)
- ‚úÖ Testes devem passar ap√≥s implementa√ß√£o (GREEN)
- ‚úÖ `pytest -q` passando

**Sem isso ‚Üí N√ÉO avan√ßa**

---

### ‚úÖ Gate Z1 ‚Äî coverage_report.json como "Fonte √önica"

**Objetivo ENDFIRST**: Implementar primeiro a estrutura de cobertura e o Quality Gate que apenas l√™ (n√£o recalcula).

**Implementa√ß√£o**:
- ‚úÖ Estrutura de `coverage_report.json` definida
- ‚úÖ `quality_gate.py` que apenas l√™ o report (n√£o recalcula nada)

**Testes obrigat√≥rios**:
- ‚úÖ Sem arquivo ‚Üí FAIL
- ‚úÖ JSON inv√°lido ‚Üí FAIL
- ‚úÖ 99% coverage ‚Üí FAIL
- ‚úÖ 100% coverage ‚Üí PASS

**Entrega obrigat√≥ria**:
- ‚úÖ `EVIDENCIAS/coverage_report.json` de exemplo (fixture)
- ‚úÖ `src/tests/unit/test_quality_gate_from_coverage_report.py`
- ‚úÖ `pytest -q` passando

**Sem isso ‚Üí N√ÉO avan√ßa**

---

### ‚úÖ Gate Z2 ‚Äî Auditoria Determin√≠stica Anti-Fraude (Sem LLM)

**Objetivo ENDFIRST**: Implementar auditoria que funciona sem IA, apenas com regex e valida√ß√µes determin√≠sticas.

**Implementa√ß√£o**:
- ‚úÖ `recall_auditor.py` com regex e valida√ß√µes
- ‚úÖ Marcador obrigat√≥rio: `[[RS:cap(\d+):([a-f0-9]{6})|(chunks|src):...]]`

**Valida√ß√µes determin√≠sticas**:
- ‚úÖ Marker encontrado
- ‚úÖ `item_id` existe no `recall_set.critical_items`
- ‚úÖ Possui m√≠nimo 1 chunk
- ‚úÖ Chunks no marker pertencem a `source_chunks` do item

**Testes obrigat√≥rios**:
- ‚úÖ Missing marker ‚Üí FAIL
- ‚úÖ Marker com chunks vazios ‚Üí FAIL
- ‚úÖ Marker com chunk inexistente ‚Üí FAIL
- ‚úÖ Marker ok ‚Üí PASS
- ‚úÖ Marker inventado ‚Üí FAIL

**Entrega obrigat√≥ria**:
- ‚úÖ `src/recall_auditor.py` implementado
- ‚úÖ `src/tests/unit/test_recall_auditor.py`
- ‚úÖ `pytest -q` passando

**Sem isso ‚Üí N√ÉO avan√ßa**

---

### ‚úÖ Gate Z3 ‚Äî IDs Imut√°veis (Determinismo)

**Objetivo ENDFIRST**: Garantir que IDs s√£o determin√≠sticos e imut√°veis.

**Implementa√ß√£o**:
- ‚úÖ Fun√ß√£o de normaliza√ß√£o + hash curto SHA256
- ‚úÖ `item_id = f"RS:cap{chapter_number}:{hash_curto}"`

**Testes obrigat√≥rios**:
- ‚úÖ Mesmo texto normalizado ‚Üí mesmo `item_id`
- ‚úÖ Mudan√ßa m√≠nima ‚Üí `item_id` muda
- ‚úÖ Normaliza√ß√£o remove pontua√ß√£o e espa√ßos redundantes

**Entrega obrigat√≥ria**:
- ‚úÖ Fun√ß√£o de normaliza√ß√£o implementada
- ‚úÖ `src/tests/unit/test_item_id_immutability.py`
- ‚úÖ `pytest -q` passando

**Sem isso ‚Üí N√ÉO avan√ßa**

---

### ‚úÖ Gate Z4 ‚Äî Recall Set com Hard Cap (12 Cr√≠ticos)

**Objetivo ENDFIRST**: Implementar gera√ß√£o de Recall Set com limites determin√≠sticos.

**Implementa√ß√£o**:
- ‚úÖ Criticidade por enum (`CriticalityReason`)
- ‚úÖ Hard cap 12 em `critical_items`
- ‚úÖ Desempate determin√≠stico (freq > posi√ß√£o > marcador)

**Teste obrigat√≥rio**:
- ‚úÖ Gerar 20 cr√≠ticos ‚Üí retorna 12 sempre iguais na mesma ordem

**Entrega obrigat√≥ria**:
- ‚úÖ `src/chunk_extractor.py` com agrega√ß√£o e hard cap
- ‚úÖ `src/tests/unit/test_recall_set_hard_cap.py`
- ‚úÖ `pytest -q` passando

**Sem isso ‚Üí N√ÉO avan√ßa**

---

### ‚úÖ Gate Z5 ‚Äî Pipeline Completo com Loop de Regenera√ß√£o

**Objetivo ENDFIRST**: Integrar tudo com loop de regenera√ß√£o e valida√ß√£o final.

**Refatora√ß√£o de `chapter_summarizer.py`**:
- ‚úÖ Chunking por cap√≠tulo
- ‚úÖ Extra√ß√£o por chunk (pode mockar LLM nos testes)
- ‚úÖ Gerar recall set
- ‚úÖ Gerar resumo COM marcadores e ancoragem
- ‚úÖ Auditoria determin√≠stica
- ‚úÖ Se falhar ‚Üí regenerar at√© 3x
- ‚úÖ Se falhar ap√≥s 3x ‚Üí erro expl√≠cito, sem output parcial

**Teste de integra√ß√£o obrigat√≥rio**:
- ‚úÖ Mock LLM gera resumo falho 2x e correto na 3¬™
- ‚úÖ Valida `regeneration_count` e coverage 100%

**Entrega obrigat√≥ria**:
- ‚úÖ `src/chapter_summarizer.py` refatorado
- ‚úÖ `src/tests/integration/test_pipeline_regeneration.py`
- ‚úÖ `pytest -q` passando

**Sem isso ‚Üí N√ÉO avan√ßa**

---

## Regras de Desenvolvimento (Obrigat√≥rias)

- ‚úÖ **TDD obrigat√≥rio**: RED ‚Üí GREEN ‚Üí REFACTOR
- ‚úÖ **Cobertura m√≠nima**: 80% (`pytest-cov`)
- ‚úÖ **Type hints + docstrings**: Todas as fun√ß√µes p√∫blicas
- ‚úÖ **Logging**: Usar `logging`, nada de `print()`
- ‚úÖ **Commits at√¥micos**: Um commit = uma funcionalidade/teste completo

---

## Entrega Final

**Rodar com um livro real e gerar**:
- ‚úÖ `EVIDENCIAS/coverage_report.json` (100%)
- ‚úÖ Extra√ß√µes por chunk em JSON
- ‚úÖ Relat√≥rio MD final

---

## Como Acompanhar (Sem Ler C√≥digo)

**A cada Gate voc√™ deve entregar**:
1. ‚úÖ Sa√≠da do `pytest -q`
2. ‚úÖ Arquivos criados/modificados (lista)
3. ‚úÖ Se houver, `EVIDENCIAS/coverage_report.json` ou fixtures

**Se um gate falhar, voc√™ para e corrige antes de seguir.**

---

## Instru√ß√µes para o Cursor (Curto e Direto)

**Mensagem obrigat√≥ria ao iniciar desenvolvimento**:

1. **"Siga o plano exatamente na ordem ENDFIRST. Gates Z0 ‚Üí Z5 s√£o bloqueantes."**
2. **"N√£o avance para a pr√≥xima etapa sem me entregar o gate atual com evid√™ncias."**
3. **"Cada gate precisa terminar com `pytest -q` passando e com os artefatos em `/EVIDENCIAS` quando aplic√°vel."**
4. **"Se o contrato mudar no meio, pare e proponha diff do contrato antes de codar."**
5. **"Comece provando que o sistema falha sem cumprir o contrato (Gate Z0)."**

**Recomenda√ß√£o**: Cobrar **Gate Z0 ‚Üí Gate Z1** primeiro. Se passar nesses dois, o resto tende a ficar sob controle.

---

## Pr√≥ximos Passos (ORDEM CORRETA)

1. **Definir contrato do Recall Set + Auditoria determin√≠stica** (TODO 0 - BLOQUEANTE)
   - Formato JSON do recall set com `item_id` (hash imut√°vel), `critical`/`supporting`
   - Enum `CriticalityReason` (MULTI_CHUNK, STRUCTURAL_POSITION, DEFINITION_MARKER, LAW_MARKER)
   - Regra de marcadores `[[RS:cap(\d+):hash|chunks:N,M]]` com evid√™ncia de ancoragem (anti-fraude)
   - Regra da auditoria: validar marcadores + chunks referenciados ‚Üí passa/falha (determin√≠stico)
   - Regras mec√¢nicas de criticidade (‚â•2 chunks, heading, defini√ß√£o, lei)
   - Hard cap: m√°ximo 12 itens `critical` por cap√≠tulo
   - Estrutura do `coverage_report.json` (matriz bin√°ria de cobertura)

2. **Atualizar `.cursorrules`** com regras m√≠nimas (TODO 0.1)
   - TDD + estrutura de testes
   - Regra de marcadores no resumo
   - Regra de evid√™ncias

3. Adicionar depend√™ncias de testes (`pytest`, `pytest-cov`, `pytest-mock`) ao `requirements.txt`
4. Criar estrutura de diret√≥rios de testes (`src/tests/unit/`, `src/tests/integration/`, `src/tests/fixtures/`)
5. Implementar `chunk_extractor.py` (com testes TDD, seguindo contrato do Recall Set)
6. Implementar `recall_auditor.py` (com testes TDD, auditoria determin√≠stica primeiro)
7. Refatorar `chapter_summarizer.py` para usar novo pipeline (com testes)
8. Atualizar `quality_gate.py` com valida√ß√£o de cobertura (com testes)
9. Atualizar `evidence_generator.py` com relat√≥rio estruturado (com testes)
10. Integrar tudo em `summarizer.py` (com testes de integra√ß√£o)
11. Garantir cobertura de testes >= 80% e executar todos os testes
12. Testar pipeline completo com livro real
13. Gerar evid√™ncias e validar todos os crit√©rios bin√°rios
14. Code review e refatora√ß√£o final
